{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e17025e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import random # for splitting the dataset randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3966d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3c37a8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data/stanford_dogs/Images\"\n",
    "OUTPUT_DIR = \"data/Processed\"\n",
    "IMG_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bd8d658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_dir):\n",
    "    all_paths = glob(os.path.join(data_dir, \"*\", \"*.jpg\"))\n",
    "    all_labels = [os.path.basename(os.path.dirname(p)) for p in all_paths]\n",
    "    return all_paths, all_labels\n",
    "\n",
    "# image_paths, labels = load_dataset(DATA_DIR)\n",
    "# print(f\"Found {len(image_paths)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "68e7e6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, target_size=IMG_SIZE):\n",
    "    \"\"\"Resize the image to the target size.\"\"\"\n",
    "    return cv2.resize(image, target_size, interpolation=cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8c39368f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    \"\"\"Normalize image pixel values to the range [0.0, 1.0].\"\"\"\n",
    "    return image.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9b5ec638",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_image(path,\n",
    "                     target_size=IMG_SIZE,\n",
    "                     to_rgb=True,\n",
    "                     normalize=True):\n",
    "    \"\"\"\n",
    "    Load and preprocess an image from a given path:\n",
    "    1) Read image file\n",
    "    2) Convert BGR to RGB (if enabled)\n",
    "    3) Resize to target size\n",
    "    4) Normalize pixel values (if enabled)\n",
    "    Returns the processed image or None if loading fails.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(path)\n",
    "    if img is None:\n",
    "        return None\n",
    "\n",
    "    if to_rgb:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    img = resize_image(img, target_size)\n",
    "\n",
    "    if normalize:\n",
    "        img = normalize_image(img)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f23cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20580 images\n",
      "Train: 14355 images (69.75%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9208637fa1c743b7b77edaf90feaf569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing:   0%|          | 0/20580 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 3025 images (14.70%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33be0c4136e6405f815439cebf776273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing:   0%|          | 0/20580 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 3200 images (15.55%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261f5c1ccaa44115929219594fcd3c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing:   0%|          | 0/20580 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# for path, label in tqdm(zip(image_paths, labels), total=len(image_paths)):\n",
    "#     image = cv2.imread(path)\n",
    "#     if image is None:\n",
    "#         continue\n",
    "    \n",
    "#      image = resize_image(image)\n",
    "#      image = normalize_image(image)\n",
    "#      image = preprocess_image(image)\n",
    "    \n",
    "#     save_path = os.path.join(OUTPUT_DIR, label)\n",
    "#     os.makedirs(save_path, exist_ok=True)\n",
    "#     filename = os.path.basename(path)\n",
    "    \n",
    "#     save_img = (np.clip(image, 0, 1) * 255).astype(np.uint8)\n",
    "#     cv2.imwrite(os.path.join(save_path, filename), save_img)\n",
    "if __name__ == \"__main__\":\n",
    "    image_paths, labels = load_dataset(DATA_DIR)\n",
    "    print(f\"Found {len(image_paths)} images\")\n",
    "\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    # Split the ratios:these are the ratios used for \n",
    "    # how much each dataset\n",
    "    SPLIT_RATIOS = {\n",
    "        \"train\": 0.7,\n",
    "        \"validation\": 0.15,\n",
    "        \"test\": 0.15\n",
    "    }\n",
    "\n",
    "    # Group paths by class, this ensures that each data split of train test and validation\n",
    "    # contains examples of all breeds\n",
    "    class_to_paths = {}\n",
    "    \n",
    "    for path, label in zip(image_paths, labels):\n",
    "        if label not in class_to_paths:\n",
    "           class_to_paths[label] = [] \n",
    "        class_to_paths[label].append(path)\n",
    "\n",
    "    # assign each path to a split\n",
    "    path_to_split = {}\n",
    "    for label, paths in class_to_paths.items(): #for each dogbreed, get all its images\n",
    "        # randomize the images going into each one by shuffling\n",
    "        random.shuffle(paths)\n",
    "        total = len(paths)\n",
    "        train_end = int(SPLIT_RATIOS[\"train\"] * total)\n",
    "        val_end = train_end + int(SPLIT_RATIOS[\"validation\"] * total)\n",
    "\n",
    "        for i, path in enumerate(paths):\n",
    "            if i < train_end:\n",
    "                path_to_split[path] = \"train\"\n",
    "            elif i < val_end:\n",
    "                path_to_split[path] = \"validation\"\n",
    "            else: #not in train or validation\n",
    "                path_to_split[path] = \"test\"\n",
    "                  \n",
    "\n",
    "    # Create folders to sepearate train,test,validation data\n",
    "    for split in SPLIT_RATIOS.keys():\n",
    "        for label in class_to_paths:\n",
    "            os.makedirs(os.path.join(OUTPUT_DIR, split, label), exist_ok=True)            \n",
    "\n",
    "    for path, label in tqdm(zip(image_paths, labels), total=len(image_paths),\n",
    "                            desc=\"Preprocessing\"):\n",
    "        img = preprocess_image(path)\n",
    "        if img is None:\n",
    "            print(f\"[READ FAIL] {path}\")  # Warn if the image could not be read\n",
    "            continue\n",
    "\n",
    "        # Convert back to 0–255 and RGB→BGR before saving\n",
    "        save_img = (img * 255).astype(np.uint8)\n",
    "        save_img = cv2.cvtColor(save_img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        split = path_to_split.get(path, \"train\")\n",
    "        save_dir = os.path.join(OUTPUT_DIR, split, label)\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        cv2.imwrite(os.path.join(save_dir, os.path.basename(path)), save_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5692bfe8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dogbreed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
