{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e17025e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c37a8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data/stanford_dogs/Images\"\n",
    "OUTPUT_DIR = \"data/Processed\"\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 150\n",
    "LR = 0.001\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd8d658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_dir):\n",
    "    all_paths = glob(os.path.join(data_dir, \"*\", \"*.jpg\"))\n",
    "    all_labels = [os.path.basename(os.path.dirname(p)) for p in all_paths]\n",
    "    return all_paths, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68e7e6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, target_size=IMG_SIZE):\n",
    "    return cv2.resize(image, target_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "def normalize_image(image):\n",
    "    return image.astype(np.float32) / 255.0\n",
    "\n",
    "def preprocess_image(path, target_size=IMG_SIZE, to_rgb=True, normalize=True):\n",
    "    img = cv2.imread(path)\n",
    "    if img is None:\n",
    "        return None\n",
    "    if to_rgb:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = resize_image(img, target_size)\n",
    "    if normalize:\n",
    "        img = normalize_image(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eb1392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=0.05):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}(mean={self.mean}, std={self.std})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d72a42c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this version is commented for now due to too high complexity (training time takes too long :L)\n",
    "# final_transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.RandomApply([transforms.GaussianBlur(kernel_size=5)], p=0.3),\n",
    "#     transforms.RandomApply([AddGaussianNoise(0., 0.1)], p=0.3),\n",
    "#     transforms.RandomApply([transforms.RandomErasing(p=1.0, scale=(0.1, 0.2))], p=0.3),\n",
    "#     transforms.RandomHorizontalFlip(p=0.5),\n",
    "#     transforms.RandomVerticalFlip(p=0.3),\n",
    "#     transforms.RandomRotation(degrees=15),\n",
    "#     transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.8, 1.2)),\n",
    "#     transforms.RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0)),\n",
    "#     transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.05),\n",
    "#     transforms.RandomGrayscale(p=0.2),\n",
    "#     transforms.RandomAdjustSharpness(sharpness_factor=2.0, p=0.5),\n",
    "#     transforms.Normalize(mean, std)\n",
    "# ])\n",
    "# Transfomations applied using def get_transform_for_epoch\n",
    "final_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80f23cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_save_dataset(image_paths, labels):\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    SPLIT_RATIOS = {\"train\": 0.7, \"validation\": 0.15, \"test\": 0.15}\n",
    "\n",
    "    class_to_paths = {}\n",
    "    for path, label in zip(image_paths, labels):\n",
    "        class_to_paths.setdefault(label, []).append(path)\n",
    "\n",
    "    path_to_split = {}\n",
    "    for label, paths in class_to_paths.items():\n",
    "        random.shuffle(paths)\n",
    "        total = len(paths)\n",
    "        train_end = int(SPLIT_RATIOS[\"train\"] * total)\n",
    "        val_end = train_end + int(SPLIT_RATIOS[\"validation\"] * total)\n",
    "        for i, path in enumerate(paths):\n",
    "            if i < train_end:\n",
    "                path_to_split[path] = \"train\"\n",
    "            elif i < val_end:\n",
    "                path_to_split[path] = \"validation\"\n",
    "            else:\n",
    "                path_to_split[path] = \"test\"\n",
    "\n",
    "    for split in SPLIT_RATIOS.keys():\n",
    "        for label in class_to_paths:\n",
    "            os.makedirs(os.path.join(OUTPUT_DIR, split, label), exist_ok=True)\n",
    "\n",
    "    for path, label in tqdm(zip(image_paths, labels), total=len(image_paths), desc=\"Preprocessing\"):\n",
    "        img = preprocess_image(path)\n",
    "        if img is None:\n",
    "            print(f\"[READ FAIL] {path}\")\n",
    "            continue\n",
    "        save_img = (img * 255).astype(np.uint8)\n",
    "        save_img = cv2.cvtColor(save_img, cv2.COLOR_RGB2BGR)\n",
    "        split = path_to_split.get(path, \"train\")\n",
    "        save_dir = os.path.join(OUTPUT_DIR, split, label)\n",
    "        cv2.imwrite(os.path.join(save_dir, os.path.basename(path)), save_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9226df9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample(image_path):\n",
    "    img_cv2 = cv2.imread(image_path)\n",
    "    img_rgb = cv2.cvtColor(img_cv2, cv2.COLOR_BGR2RGB)\n",
    "    img_pil = Image.fromarray(img_rgb)\n",
    "    img_tensor = final_transform(img_pil)\n",
    "    img_np = img_tensor.permute(1, 2, 0).numpy()\n",
    "    img_np = (img_np * std + mean).clip(0, 1)\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img_np)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Augmented Image\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10297a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     image_paths, labels = load_dataset(DATA_DIR)\n",
    "#     visualize_sample(image_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2624907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BaselineCNN(nn.Module):\n",
    "#     def __init__(self, num_classes):\n",
    "#         super().__init__()\n",
    "#         self.net = nn.Sequential(\n",
    "#             nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2),\n",
    "\n",
    "#             nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2),\n",
    "\n",
    "#             nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2),\n",
    "\n",
    "#             nn.Flatten(),\n",
    "#             nn.Linear(128 * 28 * 28, 256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.Linear(256, num_classes)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.net(x)\n",
    "\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "import torch.nn as nn\n",
    "\n",
    "def get_resnet_model(num_classes):\n",
    "    model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False  # Freeze backbone\n",
    "\n",
    "    in_features = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(in_features, num_classes)\n",
    "    )\n",
    "\n",
    "    # Keep fc layer trainable\n",
    "    for param in model.fc.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78321f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform_for_epoch(epoch):\n",
    "    if epoch < 5:  # very early simple input a(warming up the model with a few unaugmented epochs)\n",
    "        return transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "\n",
    "    elif epoch < 65:  #add some augmentation\n",
    "        return transforms.Compose([\n",
    "            transforms.RandomResizedCrop(size=224, scale=(0.9, 1.0)),\n",
    "            transforms.RandomHorizontalFlip(p = 0.5),\n",
    "            transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "    elif epoch < 130:  #for any epochs over 100, take this heavy full augment to make it more robust to \"altered images\"\n",
    "        return transforms.Compose([\n",
    "            transforms.RandomResizedCrop(size=224, scale=(0.85, 1.0)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.2),\n",
    "            transforms.RandomRotation(degrees=10),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "            transforms.RandomGrayscale(p=0.1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.RandomApply([transforms.GaussianBlur(kernel_size=3)], p=0.2),\n",
    "            transforms.RandomErasing(p=0.2, scale=(0.05, 0.15)),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "\n",
    "    else:  #for any epochs over 90, take this heavy full augment to make it more robust to \"altered images\"\n",
    "        #needs to debug past 100 epochs for some reason\n",
    "        return transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.RandomApply([transforms.GaussianBlur(kernel_size=5)], p=0.3),\n",
    "            transforms.RandomApply([AddGaussianNoise(0., 0.1)], p=0.3),\n",
    "            transforms.RandomApply([transforms.RandomErasing(p=1.0, scale=(0.1, 0.2))], p=0.3),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.3),\n",
    "            transforms.RandomRotation(degrees=15),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.8, 1.2)),\n",
    "            transforms.RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0)),\n",
    "            transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.05),\n",
    "            transforms.RandomGrayscale(p=0.2),\n",
    "            transforms.RandomAdjustSharpness(sharpness_factor=2.0, p=0.5),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29e3fa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate():\n",
    "    train_ds = datasets.ImageFolder(os.path.join(OUTPUT_DIR, 'train'), transform=get_transform_for_epoch(0))\n",
    "    \n",
    "    \n",
    "    # train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    # val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    \n",
    "\n",
    "    # model = BaselineCNN(num_classes=len(train_ds.classes)).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = get_resnet_model(num_classes=len(train_ds.classes)).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "    from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    val_ds = datasets.ImageFolder(os.path.join(OUTPUT_DIR, 'validation'), transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "    ]))\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, num_workers=4, pin_memory=True)\n",
    "\n",
    "    from torch.amp import GradScaler, autocast\n",
    "    scaler = GradScaler(\"cuda\")\n",
    "\n",
    "    best_val_acc = 0\n",
    "    patience = 5  # stop after 5 epochs without improvement\n",
    "    patience_counter = 0\n",
    "\n",
    "    unfreeze_at_epoch = 3\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        current_transform = get_transform_for_epoch(epoch)\n",
    "        train_ds = datasets.ImageFolder(os.path.join(OUTPUT_DIR, 'train'), transform=current_transform)\n",
    "\n",
    "        train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "        unfreeze_at_epoch = 3\n",
    "\n",
    "        if epoch == unfreeze_at_epoch:\n",
    "            print(f\"Unfreezing backbone at epoch {epoch}\")\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "            # Re-initialize optimizer with lower LR\n",
    "            optimizer = optim.Adam(model.parameters(), lr=LR * 0.1, weight_decay=1e-4)\n",
    "\n",
    "            # Recreate the scheduler using the new optimizer\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS - epoch)\n",
    "\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "\n",
    "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", leave=False)\n",
    "        for x, y in loop:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with autocast(\"cuda\"):\n",
    "                pred = model(x)\n",
    "                loss = criterion(pred, y)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            correct += (pred.argmax(1) == y).sum().item()\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "\n",
    "        train_acc = correct / len(train_ds)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for x_val, y_val in val_loader:\n",
    "                x_val, y_val = x_val.to(device), y_val.to(device)\n",
    "                preds = model(x_val)\n",
    "                val_correct += (preds.argmax(1) == y_val).sum().item()\n",
    "                val_total += y_val.size(0)\n",
    "\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")  # Save best model\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "        # Logging\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        print(f\"Learning rate is now: {scheduler.get_last_lr()[0]}\")\n",
    "        scheduler.step()\n",
    "    torch.save(model.state_dict(), \"baseline_cnn.pth\")\n",
    "    print(\"Model saved as baseline_cnn.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8525561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_paths, labels = load_dataset(DATA_DIR)\n",
    "# split_and_save_dataset(image_paths, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab889c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6683dcffcbc482990b03d224145b2cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/100:   0%|          | 0/449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1412.6423, Train Acc: 0.3503, Val Acc: 0.6764\n",
      "Learning rate is now: 0.001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35dfbd59e8eb4131bdf8667427225853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/100:   0%|          | 0/449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1024.3476, Train Acc: 0.5535, Val Acc: 0.7018\n",
      "Learning rate is now: 0.0009997532801828658\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff34f0f84c440859eb860f7d52383b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/100:   0%|          | 0/449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 971.7394, Train Acc: 0.6021, Val Acc: 0.7081\n",
      "Learning rate is now: 0.0009990133642141358\n",
      "Unfreezing backbone at epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0214d80ee5444ba3d113ebb05b942b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/100:   0%|          | 0/449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 904.4389, Train Acc: 0.6529, Val Acc: 0.7448\n",
      "Learning rate is now: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f5c2ab577bb4efd8996d4df1c8ca589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/100:   0%|          | 0/449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 721.2507, Train Acc: 0.8029, Val Acc: 0.7544\n",
      "Learning rate is now: 9.997377845227576e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "872646b63b1744d69aee22422eff6a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/100:   0%|          | 0/449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 746.1502, Train Acc: 0.7767, Val Acc: 0.7402\n",
      "Learning rate is now: 9.989514131188558e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "630e394f653e4d50a96db84babd06935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/100:   0%|          | 0/449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 689.8470, Train Acc: 0.8272, Val Acc: 0.7501\n",
      "Learning rate is now: 9.97641710583307e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d91bc5d520a94575b8f9f7a1c41522a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/100:   0%|          | 0/449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 642.7567, Train Acc: 0.8628, Val Acc: 0.7567\n",
      "Learning rate is now: 9.958100506132127e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71ba3152a7ea45c5a57852962e6a7012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/100:   0%|          | 0/449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 610.7588, Train Acc: 0.8930, Val Acc: 0.7507\n",
      "Learning rate is now: 9.934583543669453e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd04f56b82b74e8880081663ba3b2b38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/100:   0%|          | 0/449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 585.2974, Train Acc: 0.9154, Val Acc: 0.7593\n",
      "Learning rate is now: 9.905890884491197e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f29c4a219efc450f83c03396c9f95f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/100:   0%|          | 0/449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 561.8486, Train Acc: 0.9312, Val Acc: 0.7524\n",
      "Learning rate is now: 9.872052623234632e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41d4df50092246f9a27cc4ee84ca8c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/100:   0%|          | 0/449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 540.5552, Train Acc: 0.9496, Val Acc: 0.7421\n",
      "Learning rate is now: 9.833104251563057e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7423d056a25a4b889b92bd9aa066c4cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/100:   0%|          | 0/449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 529.4893, Train Acc: 0.9560, Val Acc: 0.7504\n",
      "Learning rate is now: 9.789086620939936e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99a6f9fc631a41058def302edad36982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/100:   0%|          | 0/449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 516.7150, Train Acc: 0.9645, Val Acc: 0.7369\n",
      "Learning rate is now: 9.740045899781354e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f12a3769a54142ab2121b986b088f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/100:   0%|          | 0/449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered.\n",
      "Model saved as baseline_cnn.pth\n"
     ]
    }
   ],
   "source": [
    "train_and_validate()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dogbreed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
